{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28a8de63-8b73-4b91-a6e1-2247ab86df90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Step 1:\n",
      "  Forget gate (f_t): 0.622\n",
      "  Input gate (i_t): 0.646\n",
      "  Candidate cell state (C_tilde_t): 0.604\n",
      "  Cell state (C_t): 0.390\n",
      "  Output gate (o_t): 0.690\n",
      "  Hidden state (h_t): 0.256\n",
      "\n",
      "Time Step 2:\n",
      "  Forget gate (f_t): 0.736\n",
      "  Input gate (i_t): 0.778\n",
      "  Candidate cell state (C_tilde_t): 0.901\n",
      "  Cell state (C_t): 0.988\n",
      "  Output gate (o_t): 0.846\n",
      "  Hidden state (h_t): 0.640\n",
      "\n",
      "Time Step 3:\n",
      "  Forget gate (f_t): 0.827\n",
      "  Input gate (i_t): 0.873\n",
      "  Candidate cell state (C_tilde_t): 0.980\n",
      "  Cell state (C_t): 1.672\n",
      "  Output gate (o_t): 0.934\n",
      "  Hidden state (h_t): 0.871\n",
      "\n",
      "Predicted next value: 3.483\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sigmoid activation function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Hyperbolic tangent activation function\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "# Initialize LSTM parameters\n",
    "W_f, W_hf, b_f = 0.5, 0.1, 0\n",
    "W_i, W_hi, b_i = 0.6, 0.2, 0\n",
    "W_c, W_hc, b_c = 0.7, 0.3, 0\n",
    "W_o, W_ho, b_o = 0.8, 0.4, 0\n",
    "\n",
    "# Initialize states\n",
    "h_prev, C_prev = 0, 0\n",
    "\n",
    "# Input sequence\n",
    "X = [1, 2, 3]\n",
    "\n",
    "# LSTM computation for each time step\n",
    "for t in range(len(X)):\n",
    "    x_t = X[t]\n",
    "    \n",
    "    # Forget gate\n",
    "    f_t = sigmoid(W_f * x_t + W_hf * h_prev + b_f)\n",
    "    \n",
    "    # Input gate\n",
    "    i_t = sigmoid(W_i * x_t + W_hi * h_prev + b_i)\n",
    "    \n",
    "    # Candidate cell state\n",
    "    C_tilde_t = tanh(W_c * x_t + W_hc * h_prev + b_c)\n",
    "    \n",
    "    # Cell state update\n",
    "    C_t = f_t * C_prev + i_t * C_tilde_t\n",
    "    \n",
    "    # Output gate\n",
    "    o_t = sigmoid(W_o * x_t + W_ho * h_prev + b_o)\n",
    "    \n",
    "    # Hidden state update\n",
    "    h_t = o_t * tanh(C_t)\n",
    "    \n",
    "    # Update previous states\n",
    "    h_prev, C_prev = h_t, C_t\n",
    "    \n",
    "    print(f\"Time Step {t+1}:\")\n",
    "    print(f\"  Forget gate (f_t): {f_t:.3f}\")\n",
    "    print(f\"  Input gate (i_t): {i_t:.3f}\")\n",
    "    print(f\"  Candidate cell state (C_tilde_t): {C_tilde_t:.3f}\")\n",
    "    print(f\"  Cell state (C_t): {C_t:.3f}\")\n",
    "    print(f\"  Output gate (o_t): {o_t:.3f}\")\n",
    "    print(f\"  Hidden state (h_t): {h_t:.3f}\")\n",
    "    print()\n",
    "\n",
    "# Predict the next value\n",
    "W_y, b_y = 4, 0\n",
    "y_pred = W_y * h_t + b_y\n",
    "\n",
    "print(f\"Predicted next value: {y_pred:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b01647a-461c-4299-b3f2-db247ef4f16a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Step 1:\n",
      "  Forget gate (f_t): 0.668\n",
      "  Input gate (i_t): 0.690\n",
      "  Candidate cell state (C_tilde_t): 0.716\n",
      "  Cell state (C_t): 0.494\n",
      "  Output gate (o_t): 0.731\n",
      "  Hidden state (h_t): 0.335\n",
      "\n",
      "Time Step 2:\n",
      "  Forget gate (f_t): 0.797\n",
      "  Input gate (i_t): 0.832\n",
      "  Candidate cell state (C_tilde_t): 0.950\n",
      "  Cell state (C_t): 1.184\n",
      "  Output gate (o_t): 0.888\n",
      "  Hidden state (h_t): 0.736\n",
      "\n",
      "Time Step 3:\n",
      "  Forget gate (f_t): 0.886\n",
      "  Input gate (i_t): 0.918\n",
      "  Candidate cell state (C_tilde_t): 0.993\n",
      "  Cell state (C_t): 1.961\n",
      "  Output gate (o_t): 0.960\n",
      "  Hidden state (h_t): 0.922\n",
      "\n",
      "Predicted next value: 3.874\n",
      "Mean Squared Error (Loss): 0.016\n",
      "Mean Absolute Error (Accuracy): 0.126\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sigmoid activation function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Hyperbolic tangent activation function\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "# Initialize LSTM parameters (adjusted to reach the target)\n",
    "W_f, W_hf, b_f = 0.6, 0.2, 0.1  # Adjusted forget gate weights\n",
    "W_i, W_hi, b_i = 0.7, 0.3, 0.1  # Adjusted input gate weights\n",
    "W_c, W_hc, b_c = 0.8, 0.4, 0.1  # Adjusted candidate cell state weights\n",
    "W_o, W_ho, b_o = 0.9, 0.5, 0.1  # Adjusted output gate weights\n",
    "\n",
    "# Initialize states\n",
    "h_prev, C_prev = 0, 0\n",
    "\n",
    "# Input sequence\n",
    "X = [1, 2, 3]\n",
    "\n",
    "# Target value (ground truth)\n",
    "target = 4\n",
    "\n",
    "# LSTM computation for each time step\n",
    "for t in range(len(X)):\n",
    "    x_t = X[t]\n",
    "    \n",
    "    # Forget gate\n",
    "    f_t = sigmoid(W_f * x_t + W_hf * h_prev + b_f)\n",
    "    \n",
    "    # Input gate\n",
    "    i_t = sigmoid(W_i * x_t + W_hi * h_prev + b_i)\n",
    "    \n",
    "    # Candidate cell state\n",
    "    C_tilde_t = tanh(W_c * x_t + W_hc * h_prev + b_c)\n",
    "    \n",
    "    # Cell state update\n",
    "    C_t = f_t * C_prev + i_t * C_tilde_t\n",
    "    \n",
    "    # Output gate\n",
    "    o_t = sigmoid(W_o * x_t + W_ho * h_prev + b_o)\n",
    "    \n",
    "    # Hidden state update\n",
    "    h_t = o_t * tanh(C_t)\n",
    "    \n",
    "    # Update previous states\n",
    "    h_prev, C_prev = h_t, C_t\n",
    "    \n",
    "    print(f\"Time Step {t+1}:\")\n",
    "    print(f\"  Forget gate (f_t): {f_t:.3f}\")\n",
    "    print(f\"  Input gate (i_t): {i_t:.3f}\")\n",
    "    print(f\"  Candidate cell state (C_tilde_t): {C_tilde_t:.3f}\")\n",
    "    print(f\"  Cell state (C_t): {C_t:.3f}\")\n",
    "    print(f\"  Output gate (o_t): {o_t:.3f}\")\n",
    "    print(f\"  Hidden state (h_t): {h_t:.3f}\")\n",
    "    print()\n",
    "\n",
    "# Predict the next value (adjusted linear transformation)\n",
    "W_y, b_y = 4.2, 0  # Adjusted to reach the target\n",
    "y_pred = W_y * h_t + b_y\n",
    "\n",
    "print(f\"Predicted next value: {y_pred:.3f}\")\n",
    "\n",
    "# Calculate loss (Mean Squared Error)\n",
    "mse_loss = (y_pred - target) ** 2\n",
    "print(f\"Mean Squared Error (Loss): {mse_loss:.3f}\")\n",
    "\n",
    "# Calculate accuracy (Mean Absolute Error)\n",
    "mae_accuracy = abs(y_pred - target)\n",
    "print(f\"Mean Absolute Error (Accuracy): {mae_accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5a00489a-0607-49f7-8269-0d1f94761314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.1118, Predicted: 3.6656\n",
      "Epoch 100, Loss: 0.0383, Predicted: 4.1956\n",
      "Epoch 200, Loss: 0.0001, Predicted: 3.9881\n",
      "Epoch 300, Loss: 0.0022, Predicted: 3.9531\n",
      "Epoch 400, Loss: 0.0025, Predicted: 3.9502\n",
      "Epoch 500, Loss: 0.0022, Predicted: 3.9529\n",
      "Epoch 600, Loss: 0.0019, Predicted: 3.9563\n",
      "Epoch 700, Loss: 0.0016, Predicted: 3.9597\n",
      "Epoch 800, Loss: 0.0014, Predicted: 3.9629\n",
      "Epoch 900, Loss: 0.0012, Predicted: 3.9658\n",
      "Epoch 1000, Loss: 0.0010, Predicted: 3.9685\n",
      "Epoch 1100, Loss: 0.0008, Predicted: 3.9710\n",
      "Epoch 1200, Loss: 0.0007, Predicted: 3.9734\n",
      "Epoch 1300, Loss: 0.0006, Predicted: 3.9755\n",
      "Epoch 1400, Loss: 0.0005, Predicted: 3.9774\n",
      "Epoch 1500, Loss: 0.0004, Predicted: 3.9792\n",
      "Epoch 1600, Loss: 0.0004, Predicted: 3.9809\n",
      "Epoch 1700, Loss: 0.0003, Predicted: 3.9824\n",
      "Epoch 1800, Loss: 0.0003, Predicted: 3.9839\n",
      "Epoch 1900, Loss: 0.0002, Predicted: 3.9852\n",
      "Epoch 2000, Loss: 0.0002, Predicted: 3.9864\n",
      "Epoch 2100, Loss: 0.0002, Predicted: 3.9875\n",
      "Epoch 2200, Loss: 0.0001, Predicted: 3.9885\n",
      "Epoch 2300, Loss: 0.0001, Predicted: 3.9894\n",
      "Epoch 2400, Loss: 0.0001, Predicted: 3.9903\n",
      "Epoch 2500, Loss: 0.0001, Predicted: 3.9911\n",
      "Epoch 2600, Loss: 0.0001, Predicted: 3.9918\n",
      "Epoch 2700, Loss: 0.0001, Predicted: 3.9925\n",
      "Epoch 2800, Loss: 0.0000, Predicted: 3.9931\n",
      "Epoch 2900, Loss: 0.0000, Predicted: 3.9936\n",
      "Epoch 3000, Loss: 0.0000, Predicted: 3.9942\n",
      "Epoch 3100, Loss: 0.0000, Predicted: 3.9946\n",
      "Epoch 3200, Loss: 0.0000, Predicted: 3.9951\n",
      "Epoch 3300, Loss: 0.0000, Predicted: 3.9955\n",
      "Epoch 3400, Loss: 0.0000, Predicted: 3.9958\n",
      "Epoch 3500, Loss: 0.0000, Predicted: 3.9962\n",
      "Epoch 3600, Loss: 0.0000, Predicted: 3.9965\n",
      "Epoch 3700, Loss: 0.0000, Predicted: 3.9968\n",
      "Epoch 3800, Loss: 0.0000, Predicted: 3.9970\n",
      "Epoch 3900, Loss: 0.0000, Predicted: 3.9973\n",
      "Epoch 4000, Loss: 0.0000, Predicted: 3.9975\n",
      "Epoch 4100, Loss: 0.0000, Predicted: 3.9977\n",
      "Epoch 4200, Loss: 0.0000, Predicted: 3.9979\n",
      "Epoch 4300, Loss: 0.0000, Predicted: 3.9981\n",
      "Epoch 4400, Loss: 0.0000, Predicted: 3.9982\n",
      "Epoch 4500, Loss: 0.0000, Predicted: 3.9984\n",
      "Epoch 4600, Loss: 0.0000, Predicted: 3.9985\n",
      "Epoch 4700, Loss: 0.0000, Predicted: 3.9986\n",
      "Epoch 4800, Loss: 0.0000, Predicted: 3.9987\n",
      "Epoch 4900, Loss: 0.0000, Predicted: 3.9988\n",
      "Epoch 5000, Loss: 0.0000, Predicted: 3.9989\n",
      "Epoch 5100, Loss: 0.0000, Predicted: 3.9990\n",
      "Epoch 5200, Loss: 0.0000, Predicted: 3.9991\n",
      "Epoch 5300, Loss: 0.0000, Predicted: 3.9992\n",
      "Epoch 5400, Loss: 0.0000, Predicted: 3.9993\n",
      "Epoch 5500, Loss: 0.0000, Predicted: 3.9993\n",
      "Epoch 5600, Loss: 0.0000, Predicted: 3.9994\n",
      "Epoch 5700, Loss: 0.0000, Predicted: 3.9994\n",
      "Epoch 5800, Loss: 0.0000, Predicted: 3.9995\n",
      "Epoch 5900, Loss: 0.0000, Predicted: 3.9995\n",
      "Epoch 6000, Loss: 0.0000, Predicted: 3.9996\n",
      "Epoch 6100, Loss: 0.0000, Predicted: 3.9996\n",
      "Epoch 6200, Loss: 0.0000, Predicted: 3.9996\n",
      "Epoch 6300, Loss: 0.0000, Predicted: 3.9997\n",
      "Epoch 6400, Loss: 0.0000, Predicted: 3.9997\n",
      "Epoch 6500, Loss: 0.0000, Predicted: 3.9997\n",
      "Epoch 6600, Loss: 0.0000, Predicted: 3.9997\n",
      "Epoch 6700, Loss: 0.0000, Predicted: 3.9998\n",
      "Epoch 6800, Loss: 0.0000, Predicted: 3.9998\n",
      "Epoch 6900, Loss: 0.0000, Predicted: 3.9998\n",
      "Epoch 7000, Loss: 0.0000, Predicted: 3.9998\n",
      "Epoch 7100, Loss: 0.0000, Predicted: 3.9998\n",
      "Epoch 7200, Loss: 0.0000, Predicted: 3.9998\n",
      "Epoch 7300, Loss: 0.0000, Predicted: 3.9999\n",
      "Epoch 7400, Loss: 0.0000, Predicted: 3.9999\n",
      "Epoch 7500, Loss: 0.0000, Predicted: 3.9999\n",
      "Epoch 7600, Loss: 0.0000, Predicted: 3.9999\n",
      "Epoch 7700, Loss: 0.0000, Predicted: 3.9999\n",
      "Epoch 7800, Loss: 0.0000, Predicted: 3.9999\n",
      "Epoch 7900, Loss: 0.0000, Predicted: 3.9999\n",
      "Epoch 8000, Loss: 0.0000, Predicted: 3.9999\n",
      "Epoch 8100, Loss: 0.0000, Predicted: 3.9999\n",
      "Epoch 8200, Loss: 0.0000, Predicted: 3.9999\n",
      "Epoch 8300, Loss: 0.0000, Predicted: 3.9999\n",
      "Epoch 8400, Loss: 0.0000, Predicted: 3.9999\n",
      "Epoch 8500, Loss: 0.0000, Predicted: 3.9999\n",
      "Epoch 8600, Loss: 0.0000, Predicted: 4.0000\n",
      "Epoch 8700, Loss: 0.0000, Predicted: 4.0000\n",
      "Epoch 8800, Loss: 0.0000, Predicted: 4.0000\n",
      "Epoch 8900, Loss: 0.0000, Predicted: 4.0000\n",
      "Final Predicted Value: 4.0000\n",
      "Mean Absolute Error (Accuracy): 0.0000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sigmoid activation function\n",
    "def sigmoid(x, derivative=False):\n",
    "    if derivative:\n",
    "        return sigmoid(x) * (1 - sigmoid(x))\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Hyperbolic tangent activation function\n",
    "def tanh(x, derivative=False):\n",
    "    if derivative:\n",
    "        return 1 - np.tanh(x) ** 2\n",
    "    return np.tanh(x)\n",
    "\n",
    "# Initialize LSTM parameters\n",
    "W_f, W_hf, b_f = 0.5, 0.1, 0\n",
    "W_i, W_hi, b_i = 0.6, 0.2, 0\n",
    "W_c, W_hc, b_c = 0.7, 0.3, 0\n",
    "W_o, W_ho, b_o = 0.8, 0.4, 0\n",
    "W_y, b_y = 4.0, 0  # Linear transformation weights\n",
    "\n",
    "# Learning rate for gradient descent\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Target value\n",
    "target = 4\n",
    "\n",
    "# Initialize states\n",
    "h_prev, C_prev = 0, 0\n",
    "\n",
    "# Input sequence\n",
    "X = [1, 2, 3]\n",
    "\n",
    "# Function to compute LSTM forward pass\n",
    "def lstm_forward(x, h_prev, C_prev):\n",
    "    # Forget gate\n",
    "    f_t = sigmoid(W_f * x + W_hf * h_prev + b_f)\n",
    "    # Input gate\n",
    "    i_t = sigmoid(W_i * x + W_hi * h_prev + b_i)\n",
    "    # Candidate cell state\n",
    "    C_tilde_t = tanh(W_c * x + W_hc * h_prev + b_c)\n",
    "    # Cell state update\n",
    "    C_t = f_t * C_prev + i_t * C_tilde_t\n",
    "    # Output gate\n",
    "    o_t = sigmoid(W_o * x + W_ho * h_prev + b_o)\n",
    "    # Hidden state update\n",
    "    h_t = o_t * tanh(C_t)\n",
    "    # Output prediction\n",
    "    y_pred = W_y * h_t + b_y\n",
    "    return f_t, i_t, C_tilde_t, C_t, o_t, h_t, y_pred\n",
    "\n",
    "# Function to compute LSTM backward pass and update weights\n",
    "def lstm_backward(x, h_prev, C_prev, f_t, i_t, C_tilde_t, C_t, o_t, h_t, y_pred, target):\n",
    "    global W_f, W_hf, b_f, W_i, W_hi, b_i, W_c, W_hc, b_c, W_o, W_ho, b_o, W_y, b_y\n",
    "\n",
    "    # Compute error (Mean Squared Error)\n",
    "    error = y_pred - target\n",
    "\n",
    "    # Gradient of the loss with respect to y_pred\n",
    "    d_y_pred = 2 * error\n",
    "\n",
    "    # Gradients for the linear transformation weights\n",
    "    d_W_y = d_y_pred * h_t\n",
    "    d_b_y = d_y_pred\n",
    "\n",
    "    # Gradient of the loss with respect to h_t\n",
    "    d_h_t = d_y_pred * W_y\n",
    "\n",
    "    # Gradients for the output gate\n",
    "    d_o_t = d_h_t * tanh(C_t)\n",
    "    d_W_o = d_o_t * sigmoid(o_t, derivative=True) * x\n",
    "    d_W_ho = d_o_t * sigmoid(o_t, derivative=True) * h_prev\n",
    "    d_b_o = d_o_t * sigmoid(o_t, derivative=True)\n",
    "\n",
    "    # Gradients for the cell state\n",
    "    d_C_t = d_h_t * o_t * tanh(C_t, derivative=True)\n",
    "\n",
    "    # Gradients for the forget gate\n",
    "    d_f_t = d_C_t * C_prev\n",
    "    d_W_f = d_f_t * sigmoid(f_t, derivative=True) * x\n",
    "    d_W_hf = d_f_t * sigmoid(f_t, derivative=True) * h_prev\n",
    "    d_b_f = d_f_t * sigmoid(f_t, derivative=True)\n",
    "\n",
    "    # Gradients for the input gate\n",
    "    d_i_t = d_C_t * C_tilde_t\n",
    "    d_W_i = d_i_t * sigmoid(i_t, derivative=True) * x\n",
    "    d_W_hi = d_i_t * sigmoid(i_t, derivative=True) * h_prev\n",
    "    d_b_i = d_i_t * sigmoid(i_t, derivative=True)\n",
    "\n",
    "    # Gradients for the candidate cell state\n",
    "    d_C_tilde_t = d_C_t * i_t\n",
    "    d_W_c = d_C_tilde_t * tanh(C_tilde_t, derivative=True) * x\n",
    "    d_W_hc = d_C_tilde_t * tanh(C_tilde_t, derivative=True) * h_prev\n",
    "    d_b_c = d_C_tilde_t * tanh(C_tilde_t, derivative=True)\n",
    "\n",
    "    # Update weights using gradient descent\n",
    "    W_f -= learning_rate * d_W_f\n",
    "    W_hf -= learning_rate * d_W_hf\n",
    "    b_f -= learning_rate * d_b_f\n",
    "\n",
    "    W_i -= learning_rate * d_W_i\n",
    "    W_hi -= learning_rate * d_W_hi\n",
    "    b_i -= learning_rate * d_b_i\n",
    "\n",
    "    W_c -= learning_rate * d_W_c\n",
    "    W_hc -= learning_rate * d_W_hc\n",
    "    b_c -= learning_rate * d_b_c\n",
    "\n",
    "    W_o -= learning_rate * d_W_o\n",
    "    W_ho -= learning_rate * d_W_ho\n",
    "    b_o -= learning_rate * d_b_o\n",
    "\n",
    "    W_y -= learning_rate * d_W_y\n",
    "    b_y -= learning_rate * d_b_y\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 9000\n",
    "for epoch in range(num_epochs):\n",
    "    h_prev, C_prev = 0, 0  # Reset hidden and cell states for each epoch\n",
    "    for t in range(len(X)):\n",
    "        x_t = X[t]\n",
    "        f_t, i_t, C_tilde_t, C_t, o_t, h_t, y_pred = lstm_forward(x_t, h_prev, C_prev)\n",
    "        lstm_backward(x_t, h_prev, C_prev, f_t, i_t, C_tilde_t, C_t, o_t, h_t, y_pred, target)\n",
    "        h_prev, C_prev = h_t, C_t  # Update hidden and cell states\n",
    "\n",
    "    # Print loss every 100 epochs\n",
    "    if epoch % 100 == 0:\n",
    "        loss = (y_pred - target) ** 2\n",
    "        print(f\"Epoch {epoch}, Loss: {loss:.4f}, Predicted: {y_pred:.4f}\")\n",
    "\n",
    "# Final prediction\n",
    "h_prev, C_prev = 0, 0\n",
    "for t in range(len(X)):\n",
    "    x_t = X[t]\n",
    "    f_t, i_t, C_tilde_t, C_t, o_t, h_t, y_pred = lstm_forward(x_t, h_prev, C_prev)\n",
    "    h_prev, C_prev = h_t, C_t\n",
    "\n",
    "print(f\"Final Predicted Value: {y_pred:.4f}\")\n",
    "\n",
    "# Calculate accuracy (Mean Absolute Error)\n",
    "mae = abs(y_pred - target)\n",
    "print(f\"Mean Absolute Error (Accuracy): {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cd64f1-641f-462f-864c-b15b11a9f2fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
